{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Intro"
      ],
      "metadata": {
        "id": "96vMMWQKzbMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-beam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzgjZIsTzd16",
        "outputId": "599a3f52-5d20-44ab-a730-e951f633e7e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (3.10.12)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam)\n",
            "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam)\n",
            "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (24.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.25.5)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2024.11.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.32.3)\n",
            "Collecting sortedcontainers>=2.4.0 (from apache-beam)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (6.0.2)\n",
            "Collecting pyarrow<17.0.0,>=3.0.0 (from apache-beam)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.22.3)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2024.12.14)\n",
            "Downloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crcmod, dill, hdfs, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=d0097874f9a9b71f88f2a32f2c865fc442ad455dc42e2c1ceb4b7cdfecdf8359\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=5f6bdaa731477e7fad0141fe4bcb9e2366188f4c7f6481adeed04ad9f5af7c40\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=a4d706e40478ab1e7fedeb8a1fbe68d04dea07551ed03a2721b559c2cfbdc535\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7d42744855eaf7588b5cbbbcb20cb94bb771cbf1487ccaf3a4a0aabca6805a2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs docopt\n",
            "Installing collected packages: sortedcontainers, docopt, crcmod, zstandard, redis, pydot, pyarrow-hotfix, pyarrow, objsize, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, cloudpickle, pymongo, hdfs, apache-beam\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.3\n",
            "    Uninstalling pydot-3.0.3:\n",
            "      Successfully uninstalled pydot-3.0.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.1\n",
            "    Uninstalling jsonpickle-4.0.1:\n",
            "      Successfully uninstalled jsonpickle-4.0.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.61.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 objsize-0.7.0 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pymongo-4.10.1 redis-5.2.1 sortedcontainers-2.4.0 zstandard-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.transforms.core import DoFn"
      ],
      "metadata": {
        "id": "zZp8ECeqzeOD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code"
      ],
      "metadata": {
        "id": "CQDc1bDCzXhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`beam.CombineFn` to klasa w Apache Beam używana do definiowania niestandardowych operacji agregujących, które łączą wiele elementów w pojedynczą wartość. Jest szczególnie przydatna, gdy domyślne funkcje agregacji (np. `beam.CombinePerKey(sum)`) są niewystarczające i wymagane jest bardziej zaawansowane lub niestandardowe przetwarzanie."
      ],
      "metadata": {
        "id": "p4vlqcA30nid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Jsg_r7JCzKh_",
        "outputId": "41ee87fa-6740-4fe0-f196-4a648c6d80b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x791237256710>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "class AverageFn(beam.CombineFn):\n",
        "    # beam.CombineFn składa się z czterech kluczowych metod, które definiują różne etapy agregacji:\n",
        "\n",
        "    # 1. create_accumulator()\n",
        "    # • Tworzy pusty akumulator, który będzie używany do zbierania danych.\n",
        "    def create_accumulator(self):\n",
        "        return (0.0, 0)   # initialize (sum, count)\n",
        "\n",
        "    # 2. add_input()\n",
        "    # • Dodaje pojedynczy element do akumulatora.\n",
        "    def add_input(self, sum_count, input):\n",
        "        (sum, count) = sum_count\n",
        "        return sum + input, count + 1\n",
        "\n",
        "    # 3. merge_accumulators()\n",
        "    # • Łączy wiele akumulatorów w jeden.\n",
        "    def merge_accumulators(self, accumulators):\n",
        "        ind_sums, ind_counts = zip(*accumulators)  # zip - [(27, 3), (39, 3), (18, 2)]  -->   [(27,39,18), (3,3,2)]\n",
        "        return sum(ind_sums), sum(ind_counts)      # (84,8)\n",
        "\n",
        "    # 4. extract_output()\n",
        "    # • Wyodrębnia końcową wartość wyjściową z akumulatora.\n",
        "    def extract_output(self, sum_count):\n",
        "        (sum, count) = sum_count\n",
        "        return sum / count if count else float('NaN')\n",
        "\n",
        "# Inicjalizacja potoku\n",
        "p = beam.Pipeline()\n",
        "\n",
        "# Przykład użycia CombineGlobally\n",
        "small_sum = (\n",
        "    p\n",
        "    | beam.Create([15, 5, 7, 7, 9, 23, 13, 5])  # Tworzenie danych wejściowych\n",
        "    | \"Combine Globally\" >> beam.CombineGlobally(AverageFn())  # Użycie CombineGlobally z AverageFn\n",
        "    | 'Write results' >> beam.io.WriteToText('data/combine')  # Zapis wyników do pliku\n",
        ")\n",
        "\n",
        "# Uruchomienie potoku\n",
        "p.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{'head -n 20 data/combine-00000-of-00001'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUOMZl7Fzs2v",
        "outputId": "13b53d15-949e-4892-9dc8-a129afb8fbcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# {Średnia} = {Suma elementów} / {Liczba elementów} = {84} / {8} = 10.5\n"
      ],
      "metadata": {
        "id": "VVeW2hbN2wWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageFn(beam.CombineFn):\n",
        "    # beam.CombineFn składa się z czterech kluczowych metod, które definiują różne etapy agregacji:\n",
        "\n",
        "    # 1. create_accumulator()\n",
        "    # • Tworzy pusty akumulator, który będzie używany do zbierania danych.\n",
        "    # • W tym przypadku akumulator to krotka (sum, count), gdzie:\n",
        "    #   - sum: przechowuje sumę wszystkich elementów\n",
        "    #   - count: przechowuje liczbę elementów\n",
        "    def create_accumulator(self):\n",
        "        return (0.0, 0)  # Inicjalizacja akumulatora jako (0.0, 0)\n",
        "\n",
        "    # 2. add_input()\n",
        "    # • Dodaje pojedynczy element do akumulatora.\n",
        "    # • Aktualizuje akumulator przez dodanie nowego elementu do sumy\n",
        "    #   i zwiększenie licznika elementów o 1.\n",
        "    def add_input(self, sum_count, input):\n",
        "        (sum, count) = sum_count  # Rozpakowanie bieżącego akumulatora\n",
        "        return sum + input, count + 1  # Zaktualizowany akumulator z nową sumą i licznikiem\n",
        "\n",
        "    # 3. merge_accumulators()\n",
        "    # • Łączy wiele akumulatorów w jeden.\n",
        "    # • Używane w systemach rozproszonych, gdzie częściowe akumulatory muszą być scalane.\n",
        "    def merge_accumulators(self, accumulators):\n",
        "        # Rozpakowanie listy akumulatorów na osobne sumy i liczniki\n",
        "        ind_sums, ind_counts = zip(*accumulators)\n",
        "        # Zwrócenie scalonego akumulatora jako sumy wszystkich sum i sumy liczników\n",
        "        return sum(ind_sums), sum(ind_counts)\n",
        "\n",
        "    # 4. extract_output()\n",
        "    # • Wyodrębnia końcową wartość wyjściową z akumulatora.\n",
        "    # • Na końcu oblicza średnią jako suma / licznik.\n",
        "    # • Jeżeli licznik jest równy 0, zwracana jest wartość NaN, aby uniknąć błędu dzielenia przez 0.\n",
        "    def extract_output(self, sum_count):\n",
        "        (sum, count) = sum_count  # Rozpakowanie końcowego akumulatora\n",
        "        return sum / count if count else float('NaN')  # Obliczenie średniej lub zwrócenie NaN\n",
        "\n",
        "# Inicjalizacja potoku\n",
        "p = beam.Pipeline()\n",
        "\n",
        "# Przykład użycia CombineGlobally\n",
        "small_sum = (\n",
        "    p\n",
        "    | beam.Create([15, 5, 7, 7, 9, 23, 13, 5])  # Tworzenie danych wejściowych\n",
        "    # • Użycie transformacji CombineGlobally z AverageFn\n",
        "    # • Dane wejściowe są przekazywane do CombineFn, który oblicza średnią\n",
        "    | \"Combine Globally\" >> beam.CombineGlobally(AverageFn())\n",
        "    # Zapisanie wyniku do pliku tekstowego o nazwie 'data/combine'\n",
        "    | 'Write results' >> beam.io.WriteToText('data/combine')\n",
        ")\n",
        "\n",
        "# Uruchomienie potoku\n",
        "p.run()"
      ],
      "metadata": {
        "id": "x_Svnh6U5t4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageFn(beam.CombineFn):\n",
        "    def create_accumulator(self):\n",
        "        accumulator = (0.0, 0)\n",
        "        print(accumulator) # (0.0, 0)\n",
        "        return accumulator\n",
        "\n",
        "    def add_input(self, sum_count, input):\n",
        "        (sum, count) = sum_count\n",
        "        updated_accumulator = (sum + input, count + 1)\n",
        "        print(updated_accumulator)\n",
        "        # (15.0, 1)\n",
        "        # (20.0, 2)\n",
        "\n",
        "        return updated_accumulator\n",
        "\n",
        "    def merge_accumulators(self, accumulators):\n",
        "        print(accumulators) # [(84.0, 8)]\n",
        "\n",
        "        ind_sums, ind_counts = zip(*accumulators)\n",
        "        merged_accumulator = (sum(ind_sums), sum(ind_counts))\n",
        "        print(merged_accumulator) # (84.0, 8)\n",
        "        return merged_accumulator\n",
        "\n",
        "    def extract_output(self, sum_count):\n",
        "        (sum, count) = sum_count\n",
        "        result = sum / count if count else float('NaN')\n",
        "        print(f\"{sum}, {count}, {result}\") # 84.0, 8, 10.5\n",
        "        return result\n",
        "\n",
        "# Inicjalizacja potoku\n",
        "p = beam.Pipeline()\n",
        "\n",
        "# Przykład użycia CombineGlobally\n",
        "small_sum = (\n",
        "    p\n",
        "    | beam.Create([15, 5, 7, 7, 9, 23, 13, 5])  # Tworzenie danych wejściowych\n",
        "    | \"Combine Globally\" >> beam.CombineGlobally(AverageFn())  # Użycie CombineGlobally z AverageFn\n",
        "    | 'Write results' >> beam.io.WriteToText('data/combine')  # Zapis wyników do pliku\n",
        ")\n",
        "\n",
        "# Uruchomienie potoku\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFrEjCPT68hQ",
        "outputId": "996f19c8-0990-49d4-9809-8a14f19400c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0, 0)\n",
            "(15.0, 1)\n",
            "(20.0, 2)\n",
            "(27.0, 3)\n",
            "(34.0, 4)\n",
            "(43.0, 5)\n",
            "(66.0, 6)\n",
            "(79.0, 7)\n",
            "(84.0, 8)\n",
            "[(84.0, 8)]\n",
            "(84.0, 8)\n",
            "84.0, 8, 10.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x791237254ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oblicza różnicę między maksymalną a minimalną wartością (max_value - min_value)."
      ],
      "metadata": {
        "id": "d1NnkXlNB15Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "class MaxDifferenceFn(beam.CombineFn):\n",
        "    # Tworzymy akumulator przechowujący minimum i maksimum\n",
        "    def create_accumulator(self):\n",
        "        accumulator = (float('inf'), float('-inf'))  # (min_value, max_value)\n",
        "        print(f\"create_accumulator: {accumulator}\")\n",
        "        # create_accumulator: (inf, -inf)\n",
        "        return accumulator\n",
        "\n",
        "    # Aktualizujemy akumulator o wartość elementu wejściowego\n",
        "    def add_input(self, min_max, input):\n",
        "        (current_min, current_max) = min_max\n",
        "        updated_accumulator = (min(current_min, input), max(current_max, input))\n",
        "        print(f\"add_input - input: {input}, updated_accumulator: {updated_accumulator}\")\n",
        "        # add_input - input: 15, updated_accumulator: (15, 15)\n",
        "        # add_input - input: 5, updated_accumulator: (5, 15)\n",
        "        # add_input - input: 7, updated_accumulator: (5, 15)\n",
        "        # add_input - input: 7, updated_accumulator: (5, 15)\n",
        "        # add_input - input: 9, updated_accumulator: (5, 15)\n",
        "        # add_input - input: 23, updated_accumulator: (5, 23)\n",
        "        # add_input - input: 13, updated_accumulator: (5, 23)\n",
        "        # add_input - input: 5, updated_accumulator: (5, 23)\n",
        "        return updated_accumulator\n",
        "\n",
        "    # Scalanie akumulatorów (np. przy obliczeniach rozproszonych)\n",
        "    def merge_accumulators(self, accumulators):\n",
        "        print(f\"merge_accumulators - incoming accumulators: {accumulators}\")\n",
        "        # merge_accumulators - incoming accumulators: [(5, 23)]\n",
        "        min_values, max_values = zip(*accumulators)\n",
        "        merged_accumulator = (min(min_values), max(max_values))\n",
        "        print(f\"merge_accumulators - merged_accumulator: {merged_accumulator}\")\n",
        "        # merge_accumulators - merged_accumulator: (5, 23)\n",
        "        return merged_accumulator\n",
        "\n",
        "    # Wyodrębniamy końcowy wynik (różnica max - min)\n",
        "    def extract_output(self, min_max):\n",
        "        (min_value, max_value) = min_max\n",
        "        result = max_value - min_value if min_value != float('inf') else float('NaN')\n",
        "        print(f\"extract_output - min_value: {min_value}, max_value: {max_value}, result: {result}\")\n",
        "        # extract_output - min_value: 5, max_value: 23, result: 18\n",
        "        return result\n",
        "\n",
        "# Inicjalizacja potoku\n",
        "p = beam.Pipeline()\n",
        "\n",
        "# Przykład użycia CombineGlobally\n",
        "max_difference = (\n",
        "    p\n",
        "    | beam.Create([15, 5, 7, 7, 9, 23, 13, 5])  # Tworzenie danych wejściowych\n",
        "    | \"Compute Max Difference\" >> beam.CombineGlobally(MaxDifferenceFn())  # Obliczanie maksymalnej różnicy\n",
        "    | 'Write results' >> beam.io.WriteToText('data/max_difference')  # Zapis wyników do pliku\n",
        ")\n",
        "\n",
        "# Uruchomienie potoku\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP0-qyJTBx1c",
        "outputId": "4fe9f177-dead-423f-fd10-da8a3533d77a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_accumulator: (inf, -inf)\n",
            "add_input - input: 15, updated_accumulator: (15, 15)\n",
            "add_input - input: 5, updated_accumulator: (5, 15)\n",
            "add_input - input: 7, updated_accumulator: (5, 15)\n",
            "add_input - input: 7, updated_accumulator: (5, 15)\n",
            "add_input - input: 9, updated_accumulator: (5, 15)\n",
            "add_input - input: 23, updated_accumulator: (5, 23)\n",
            "add_input - input: 13, updated_accumulator: (5, 23)\n",
            "add_input - input: 5, updated_accumulator: (5, 23)\n",
            "merge_accumulators - incoming accumulators: [(5, 23)]\n",
            "merge_accumulators - merged_accumulator: (5, 23)\n",
            "extract_output - min_value: 5, max_value: 23, result: 18\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7912352f79a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{'head -n 20 data/max_difference-00000-of-00001'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ZGbXSFB8Ci",
        "outputId": "51ad8590-2bd5-442f-e23f-d14511b74b60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    }
  ]
}